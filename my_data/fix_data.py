import os
import pandas as pd
from tqdm import tqdm
import shutil

# ================= é…ç½®åŒºåŸŸ =================
# ä½ çš„æ•°æ®æ ¹ç›®å½•
BASE_DIR = './data/futures/um/daily/klines'
# ===========================================

def fix_and_save(file_path):
    try:
        # 1. è¯»å–æ•°æ®
        df = pd.read_parquet(file_path)
        
        # 2. æ ‡å‡†åŒ–åˆ—åï¼šå°† timestamp é‡å‘½åä¸º open_time
        if 'timestamp' in df.columns:
            df.rename(columns={'timestamp': 'open_time'}, inplace=True)
            
        # 3. ç¡®ä¿æ—¶é—´ç±»å‹æ­£ç¡®
        if not pd.api.types.is_datetime64_any_dtype(df['open_time']):
            df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')

        # 4. è®¡ç®—è¡¥å…¨é€»è¾‘ (å¼ºåˆ¶é‡æ–°è®¡ç®—ï¼Œç¡®ä¿ç»Ÿä¸€)
        # CloseTime = OpenTime + 1åˆ†é’Ÿ - 1æ¯«ç§’
        df['close_time'] = df['open_time'] + pd.Timedelta(minutes=1) - pd.Timedelta(milliseconds=1)
        # Ignore = 0
        df['ignore'] = 0

        # 5. å¼ºåˆ¶åˆ—é¡ºåº (å¸å®‰æ ‡å‡† 12 åˆ—)
        target_columns = [
            'open_time',            # 1. å¼€ç›˜æ—¶é—´
            'open',                 # 2. å¼€ç›˜ä»·
            'high',                 # 3. æœ€é«˜ä»·
            'low',                  # 4. æœ€ä½ä»·
            'close',                # 5. æ”¶ç›˜ä»·
            'volume',               # 6. æˆäº¤é‡
            'close_time',           # 7. æ”¶ç›˜æ—¶é—´
            'quote_volume',         # 8. æˆäº¤é¢
            'count',                # 9. ç¬”æ•°
            'taker_buy_volume',     # 10. ä¸»åŠ¨ä¹°å…¥é‡
            'taker_buy_quote_volume',# 11. ä¸»åŠ¨ä¹°å…¥é¢
            'ignore'                # 12. å¿½ç•¥
        ]
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰åˆ—éƒ½å­˜åœ¨ (é˜²æ­¢å› åˆ—åä¸åŒ¹é…å¯¼è‡´çš„æŠ¥é”™)
        missing = [c for c in target_columns if c not in df.columns]
        if missing:
            return f"MISSING_COLS: {missing}"
            
        # æŒ‰ç…§æ ‡å‡†é¡ºåºé‡æ’
        df = df[target_columns]

        # 6. å®‰å…¨å¤‡ä»½é€»è¾‘
        # åŸæ–‡ä»¶è·¯å¾„ -> åŸæ–‡ä»¶è·¯å¾„.bak
        backup_path = file_path + ".bak"
        if not os.path.exists(backup_path):
            shutil.move(file_path, backup_path)
        
        # 7. ä¿å­˜æ–°æ–‡ä»¶ (parquet)
        df.to_parquet(file_path, index=False)
        
        return "SUCCESS"

    except Exception as e:
        # å¦‚æœå‡ºé”™äº†ï¼Œä¸”å·²ç»ç”Ÿæˆäº†å¤‡ä»½ä½†æ²¡ä¿å­˜æˆåŠŸï¼Œå°è¯•æ¢å¤
        # (è¿™é‡Œç®€å•å¤„ç†ï¼Œåªè¿”å›é”™è¯¯ä¿¡æ¯)
        return f"ERROR: {str(e)}"

def main():
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡ä¿®å¤æ•°æ®: {BASE_DIR}")
    
    # æ‰«ææ‰€æœ‰ .parquet æ–‡ä»¶ (æ’é™¤ .bak)
    files_to_fix = []
    for root, dirs, files in os.walk(BASE_DIR):
        for file in files:
            if file.endswith(".parquet") and not file.endswith(".bak"):
                files_to_fix.append(os.path.join(root, file))
    
    print(f"ğŸ“‹ å…±æ‰«æåˆ° {len(files_to_fix)} ä¸ªæ–‡ä»¶ã€‚")
    
    pbar = tqdm(files_to_fix, unit="file")
    stats = {"SUCCESS": 0, "ERROR": 0, "MISSING_COLS": 0}
    
    for file_path in pbar:
        # æ˜¾ç¤ºå½“å‰æ–‡ä»¶
        pbar.set_description(f"Processing {os.path.basename(file_path)}")
        
        result = fix_and_save(file_path)
        
        # ç»Ÿè®¡ç»“æœ
        if result == "SUCCESS":
            stats["SUCCESS"] += 1
        elif result.startswith("MISSING"):
            stats["MISSING_COLS"] += 1
        else:
            stats["ERROR"] += 1
            print(f"\nFailed on {file_path}: {result}")

    print("\n" + "="*30)
    print("âœ… æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼")
    print(f"æˆåŠŸä¿®å¤: {stats['SUCCESS']}")
    print(f"åˆ—ç¼ºå¤±è·³è¿‡: {stats['MISSING_COLS']}")
    print(f"å‘ç”Ÿé”™è¯¯: {stats['ERROR']}")
    print("="*30)
    print("\nğŸ’¡ æç¤ºï¼š")
    print("1. åŸæ–‡ä»¶å·²é‡å‘½åä¸º .bak ä¿å­˜åœ¨åŒç›®å½•ä¸‹ã€‚")
    print("2. è¯·éšæœºæŠ½æŸ¥å‡ ä¸ªæ–‡ä»¶ï¼Œç¡®ä¿æ•°æ®æ­£ç¡®ã€‚")

if __name__ == "__main__":
    main()